{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4845244,"sourceType":"datasetVersion","datasetId":2808179}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# Check what's in your input directory\nprint(\"Available datasets:\")\nfor item in os.listdir('/kaggle/input'):\n    print(f\"  - {item}\")\n\n# Look for images\nprint(\"\\nSearching for image files...\")\nfor root, dirs, files in os.walk('/kaggle/input'):\n    jpg_files = [f for f in files if f.endswith(('.jpg', '.jpeg'))]\n    if jpg_files:\n        print(f\"Found {len(jpg_files)} images in: {root}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T06:50:13.309897Z","iopub.execute_input":"2026-02-15T06:50:13.310520Z","iopub.status.idle":"2026-02-15T06:51:26.082797Z","shell.execute_reply.started":"2026-02-15T06:50:13.310490Z","shell.execute_reply":"2026-02-15T06:51:26.082064Z"}},"outputs":[{"name":"stdout","text":"Available datasets:\n  - datasets\n\nSearching for image files...\nFound 31783 images in: /kaggle/input/datasets/eeshawn/flickr30k/flickr30k_images\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os, pickle, torch, torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nfrom tqdm import tqdm\n\ndef find_image_dir():\n    # Common Kaggle root\n    base_input = '/kaggle/input'\n    # Walk through the input directory to find where the images actually are\n    for root, dirs, files in os.walk(base_input):\n        # Look for the folder containing a high volume of jpg files\n        if len([f for f in files if f.endswith('.jpg')]) > 1000:\n            return root\n    return None\n\nIMAGE_DIR = find_image_dir()\nOUTPUT_FILE = 'flickr30k_features.pkl'\n\nif IMAGE_DIR:\n    print(f\" Found images at: {IMAGE_DIR}\")\nelse:\n    # FIXED: Properly formatted error message\n    raise FileNotFoundError(\"Could not find the Flickr30k image directory. Please ensure the dataset is added to the notebook.\")\n\n# --- THE DATASET CLASS ---\nclass FlickrDataset(Dataset):\n    def __init__(self, img_dir, transform):\n        self.img_names = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg'))]\n        self.transform = transform\n        self.img_dir = img_dir\n    \n    def __len__(self):\n        return len(self.img_names)\n    \n    def __getitem__(self, idx):\n        name = self.img_names[idx]\n        img_path = os.path.join(self.img_dir, name)\n        img = Image.open(img_path).convert('RGB')\n        return self.transform(img), name\n\n# --- REMAINDER OF THE PIPELINE (AS BEFORE) ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\nmodel = nn.Sequential(*list(model.children())[:-1])  # Feature vector only\nmodel = nn.DataParallel(model).to(device)\nmodel.eval()\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n\ndataset = FlickrDataset(IMAGE_DIR, transform)\nloader = DataLoader(dataset, batch_size=128, num_workers=4)\n\nfeatures_dict = {}\nwith torch.no_grad():\n    for imgs, names in tqdm(loader, desc=\"Extracting Features\"):\n        feats = model(imgs.to(device)).view(imgs.size(0), -1)\n        for i, name in enumerate(names):\n            features_dict[name] = feats[i].cpu().numpy()\n\nwith open(OUTPUT_FILE, 'wb') as f:\n    pickle.dump(features_dict, f)\n\nprint(f\"Success! {len(features_dict)} images processed and saved to {OUTPUT_FILE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T06:53:26.199001Z","iopub.execute_input":"2026-02-15T06:53:26.199743Z","iopub.status.idle":"2026-02-15T06:55:44.806028Z","shell.execute_reply.started":"2026-02-15T06:53:26.199710Z","shell.execute_reply":"2026-02-15T06:55:44.805310Z"}},"outputs":[{"name":"stdout","text":"✓ Found images at: /kaggle/input/datasets/eeshawn/flickr30k/flickr30k_images\nDownloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 97.8M/97.8M [00:00<00:00, 192MB/s] \nExtracting Features: 100%|██████████| 249/249 [02:01<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Success! 31783 images processed and saved to flickr30k_features.pkl\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# PART 2: VOCABULARY & TEXT PRE-PROCESSING\n# ============================================================================\n\nimport os, pickle, torch, torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport re\nfrom tqdm import tqdm\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PART 2: VOCABULARY and TEXT PRE-PROCESSING\")\nprint(\"=\"*70)\n\n# Load the extracted features\nwith open('flickr30k_features.pkl', 'rb') as f:\n    features_dict = pickle.load(f)\nprint(f\" Loaded {len(features_dict)} image features\")\n\n# Find and load captions\ndef find_captions_file():\n    base_input = '/kaggle/input'\n    for root, dirs, files in os.walk(base_input):\n        for file in files:\n            if 'caption' in file.lower() and file.endswith('.txt'):\n                return os.path.join(root, file)\n    return None\n\ncaptions_file = find_captions_file()\nprint(f\" Found captions at: {captions_file}\")\n\n# Load captions (handle different formats)\ncaptions_df = pd.read_csv(captions_file, sep='|' if '|' in open(captions_file).readline() else ',')\n\n# Standardize column names\nif 'image_name' in captions_df.columns:\n    captions_df.rename(columns={'image_name': 'image'}, inplace=True)\nif 'comment' in captions_df.columns:\n    captions_df.rename(columns={'comment': 'caption'}, inplace=True)\n\ncaptions_df['caption'] = captions_df['caption'].astype(str).str.strip()\ncaptions_df = captions_df[captions_df['caption'].str.len() > 0]\n\nprint(f\"Loaded {len(captions_df)} captions for {captions_df['image'].nunique()} images\")\n\n# Build Vocabulary\nclass Vocabulary:\n    def __init__(self, freq_threshold=5):\n        self.freq_threshold = freq_threshold\n        self.word2idx = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2, \"<unk>\": 3}\n        self.idx2word = {v: k for k, v in self.word2idx.items()}\n        self.word_freq = Counter()\n        self.idx = 4\n        self.pad_token = \"<pad>\"\n        self.start_token = \"<start>\"\n        self.end_token = \"<end>\"\n        self.unk_token = \"<unk>\"\n    \n    def tokenize(self, text):\n        text = text.lower()\n        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n        return text.split()\n    \n    def build_vocabulary(self, captions_list):\n        for caption in captions_list:\n            tokens = self.tokenize(caption)\n            self.word_freq.update(tokens)\n        \n        for word, freq in self.word_freq.items():\n            if freq >= self.freq_threshold:\n                self.word2idx[word] = self.idx\n                self.idx2word[self.idx] = word\n                self.idx += 1\n        \n        print(f\"Vocabulary built: {len(self.word2idx)} words\")\n    \n    def numericalize(self, text):\n        tokens = self.tokenize(text)\n        return [self.word2idx.get(token, self.word2idx[self.unk_token]) for token in tokens]\n    \n    def decode(self, indices):\n        words = []\n        for idx in indices:\n            word = self.idx2word.get(idx, self.unk_token)\n            if word == self.end_token:\n                break\n            if word not in [self.pad_token, self.start_token]:\n                words.append(word)\n        return \" \".join(words)\n    \n    def __len__(self):\n        return len(self.word2idx)\n\nvocab = Vocabulary(freq_threshold=5)\nvocab.build_vocabulary(captions_df['caption'].tolist())\n\n# Prepare training data\ndata = []\nMAX_LENGTH = 50\n\nfor img_name, feature in tqdm(features_dict.items(), desc=\"Preparing data\"):\n    img_captions = captions_df[captions_df['image'] == img_name]['caption'].tolist()\n    \n    for caption in img_captions:\n        caption_indices = [vocab.word2idx[vocab.start_token]]\n        caption_indices.extend(vocab.numericalize(caption))\n        caption_indices.append(vocab.word2idx[vocab.end_token])\n        \n        if len(caption_indices) > MAX_LENGTH:\n            caption_indices = caption_indices[:MAX_LENGTH-1] + [vocab.word2idx[vocab.end_token]]\n        \n        data.append({\n            'image_name': img_name,\n            'feature': feature,\n            'caption': caption_indices,\n            'caption_length': len(caption_indices)\n        })\n\nprint(f\" Prepared {len(data)} training samples\")\n\n# Save vocabulary\nwith open('vocab.pkl', 'wb') as f:\n    pickle.dump(vocab, f)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T06:55:54.948942Z","iopub.execute_input":"2026-02-15T06:55:54.949678Z","iopub.status.idle":"2026-02-15T07:02:03.335096Z","shell.execute_reply.started":"2026-02-15T06:55:54.949648Z","shell.execute_reply":"2026-02-15T07:02:03.334458Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nPART 2: VOCABULARY and TEXT PRE-PROCESSING\n======================================================================\n Loaded 31783 image features\n Found captions at: /kaggle/input/datasets/eeshawn/flickr30k/captions.txt\nLoaded 158915 captions for 31783 images\nVocabulary built: 7727 words\n","output_type":"stream"},{"name":"stderr","text":"Preparing data: 100%|██████████| 31783/31783 [06:06<00:00, 86.73it/s]","output_type":"stream"},{"name":"stdout","text":" Prepared 158915 training samples\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n# PART 3: SEQ2SEQ ARCHITECTURE\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PART 3: SEQ2SEQ ARCHITECTURE\")\nprint(\"=\"*70)\n\nimport torch.nn.functional as F\n\nclass Encoder(nn.Module):\n    def __init__(self, feature_size=2048, hidden_size=512, dropout=0.5):\n        super(Encoder, self).__init__()\n        self.fc = nn.Linear(feature_size, hidden_size)\n        self.bn = nn.BatchNorm1d(hidden_size)\n        self.dropout = nn.Dropout(dropout)\n        self.relu = nn.ReLU()\n    \n    def forward(self, features):\n        encoded = self.fc(features)\n        encoded = self.bn(encoded)\n        encoded = self.relu(encoded)\n        encoded = self.dropout(encoded)\n        return encoded\n\nclass Decoder(nn.Module):\n    def __init__(self, vocab_size, embed_size=300, hidden_size=512, num_layers=1, dropout=0.5):\n        super(Decoder, self).__init__()\n        self.vocab_size = vocab_size\n        self.embed_size = embed_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.embed = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True,\n                           dropout=dropout if num_layers > 1 else 0)\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n        \n        self.init_weights()\n    \n    def init_weights(self):\n        self.embed.weight.data.uniform_(-0.1, 0.1)\n        self.fc.bias.data.fill_(0)\n        self.fc.weight.data.uniform_(-0.1, 0.1)\n    \n    def forward(self, encoded_features, captions, lengths=None):\n        embeddings = self.embed(captions)\n        embeddings = self.dropout(embeddings)\n        \n        batch_size = encoded_features.size(0)\n        h0 = encoded_features.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        c0 = torch.zeros_like(h0)\n        \n        if lengths is not None:\n            embeddings = nn.utils.rnn.pack_padded_sequence(\n                embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False\n            )\n        \n        lstm_out, _ = self.lstm(embeddings, (h0, c0))\n        \n        if lengths is not None:\n            lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n        \n        outputs = self.fc(self.dropout(lstm_out))\n        return outputs\n    \n    def generate_greedy(self, encoded_features, vocab, max_length=50):\n        batch_size = encoded_features.size(0)\n        device = encoded_features.device\n        \n        h = encoded_features.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        c = torch.zeros_like(h)\n        \n        inputs = torch.tensor([vocab.word2idx[vocab.start_token]] * batch_size).to(device)\n        inputs = inputs.unsqueeze(1)\n        \n        generated_ids = []\n        \n        for _ in range(max_length):\n            embeddings = self.embed(inputs)\n            lstm_out, (h, c) = self.lstm(embeddings, (h, c))\n            outputs = self.fc(lstm_out.squeeze(1))\n            predicted = outputs.argmax(dim=1)\n            generated_ids.append(predicted.cpu().numpy())\n            \n            if (predicted == vocab.word2idx[vocab.end_token]).all():\n                break\n            \n            inputs = predicted.unsqueeze(1)\n        \n        generated_ids = np.array(generated_ids).T\n        \n        captions = []\n        for ids in generated_ids:\n            caption = vocab.decode(ids)\n            captions.append(caption)\n        \n        return captions\n    \n    def generate_beam_search(self, encoded_features, vocab, beam_width=3, max_length=50):\n        device = encoded_features.device\n        \n        h = encoded_features.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        c = torch.zeros_like(h)\n        \n        start_idx = vocab.word2idx[vocab.start_token]\n        end_idx = vocab.word2idx[vocab.end_token]\n        \n        beams = [([start_idx], 0.0, h, c)]\n        completed = []\n        \n        for step in range(max_length):\n            candidates = []\n            \n            for seq, score, h_state, c_state in beams:\n                if seq[-1] == end_idx:\n                    completed.append((seq, score))\n                    continue\n                \n                inputs = torch.tensor([seq[-1]]).to(device).unsqueeze(0)\n                embeddings = self.embed(inputs)\n                lstm_out, (h_new, c_new) = self.lstm(embeddings, (h_state, c_state))\n                outputs = self.fc(lstm_out.squeeze(1))\n                \n                log_probs = F.log_softmax(outputs, dim=1)\n                top_probs, top_indices = log_probs.topk(beam_width, dim=1)\n                \n                for i in range(beam_width):\n                    word_idx = top_indices[0, i].item()\n                    word_prob = top_probs[0, i].item()\n                    new_seq = seq + [word_idx]\n                    new_score = score + word_prob\n                    candidates.append((new_seq, new_score, h_new, c_new))\n            \n            candidates.sort(key=lambda x: x[1], reverse=True)\n            beams = candidates[:beam_width]\n            \n            if len(beams) == 0:\n                break\n        \n        completed.extend(beams)\n        \n        if completed:\n            completed.sort(key=lambda x: x[1] / len(x[0]), reverse=True)\n            best_seq = completed[0][0]\n        else:\n            best_seq = beams[0][0] if beams else [start_idx, end_idx]\n        \n        caption = vocab.decode(best_seq)\n        return caption\n\nclass ImageCaptioningModel(nn.Module):\n    def __init__(self, vocab_size, feature_size=2048, embed_size=300, \n                 hidden_size=512, num_layers=1, dropout=0.5):\n        super(ImageCaptioningModel, self).__init__()\n        self.encoder = Encoder(feature_size, hidden_size, dropout)\n        self.decoder = Decoder(vocab_size, embed_size, hidden_size, num_layers, dropout)\n    \n    def forward(self, features, captions, lengths=None):\n        encoded = self.encoder(features)\n        outputs = self.decoder(encoded, captions, lengths)\n        return outputs\n    \n    def generate_caption(self, features, vocab, method='greedy', beam_width=3, max_length=50):\n        self.eval()\n        with torch.no_grad():\n            if features.dim() == 1:\n                features = features.unsqueeze(0)\n            \n            encoded = self.encoder(features)\n            \n            if method == 'greedy':\n                captions = self.decoder.generate_greedy(encoded, vocab, max_length)\n                return captions[0]\n            elif method == 'beam':\n                return self.decoder.generate_beam_search(encoded, vocab, beam_width, max_length)\n\nmodel = ImageCaptioningModel(vocab_size=len(vocab))\nprint(f\" Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:07:17.071718Z","iopub.execute_input":"2026-02-15T07:07:17.072066Z","iopub.status.idle":"2026-02-15T07:07:17.191717Z","shell.execute_reply.started":"2026-02-15T07:07:17.072036Z","shell.execute_reply":"2026-02-15T07:07:17.191055Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nPART 3: SEQ2SEQ ARCHITECTURE\n======================================================================\n Model created with 8,999,235 parameters\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================================\n# PART 4: TRAINING and INFERENCE\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PART 4: TRAINING and INFERENCE\")\nprint(\"=\"*70)\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\n# Dataset\nclass CaptionDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        item = self.data[idx]\n        return {\n            'feature': torch.FloatTensor(item['feature']),\n            'caption': torch.LongTensor(item['caption']),\n            'length': item['caption_length']\n        }\n\ndef collate_fn(batch):\n    batch.sort(key=lambda x: x['length'], reverse=True)\n    \n    features = torch.stack([item['feature'] for item in batch])\n    lengths = torch.LongTensor([item['length'] for item in batch])\n    \n    max_len = lengths[0].item()\n    padded_captions = torch.full((len(batch), max_len), 0, dtype=torch.long)\n    \n    for i, item in enumerate(batch):\n        caption = item['caption']\n        padded_captions[i, :len(caption)] = caption\n    \n    return features, padded_captions, lengths\n\n# Split data\ntrain_size = int(0.8 * len(data))\ntrain_data = data[:train_size]\nval_data = data[train_size:]\n\ntrain_dataset = CaptionDataset(train_data)\nval_dataset = CaptionDataset(val_data)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n\nprint(f\" Training samples: {len(train_dataset)}\")\nprint(f\" Validation samples: {len(val_dataset)}\")\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=0)\noptimizer = optim.Adam(model.parameters(), lr=3e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n\n# Training loop\ntrain_losses = []\nval_losses = []\nbest_val_loss = float('inf')\nNUM_EPOCHS = 15\n\nprint(f\"\\nStarting training for {NUM_EPOCHS} epochs...\")\nprint(\"-\" * 70)\n\nfor epoch in range(NUM_EPOCHS):\n    # Train\n    model.train()\n    total_train_loss = 0\n    \n    for features, captions, lengths in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n        features = features.to(device)\n        captions = captions.to(device)\n        lengths = lengths.to(device)\n        \n        outputs = model(features, captions[:, :-1], lengths - 1)\n        outputs = outputs.reshape(-1, outputs.size(-1))\n        targets = captions[:, 1:].reshape(-1)\n        \n        loss = criterion(outputs, targets)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n        optimizer.step()\n        \n        total_train_loss += loss.item()\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n    \n    # Validate\n    model.eval()\n    total_val_loss = 0\n    \n    with torch.no_grad():\n        for features, captions, lengths in val_loader:\n            features = features.to(device)\n            captions = captions.to(device)\n            lengths = lengths.to(device)\n            \n            outputs = model(features, captions[:, :-1], lengths - 1)\n            outputs = outputs.reshape(-1, outputs.size(-1))\n            targets = captions[:, 1:].reshape(-1)\n            \n            loss = criterion(outputs, targets)\n            total_val_loss += loss.item()\n    \n    avg_val_loss = total_val_loss / len(val_loader)\n    val_losses.append(avg_val_loss)\n    \n    scheduler.step(avg_val_loss)\n    \n    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n    \n    # Save best model\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'train_loss': avg_train_loss,\n            'val_loss': avg_val_loss,\n        }, 'best_model.pth')\n        print(f\"   Best model saved!\")\n\nprint(\"\\n Training complete!\")\n\n# Plot loss curve\nplt.figure(figsize=(10, 6))\nplt.plot(train_losses, label='Training Loss', linewidth=2)\nplt.plot(val_losses, label='Validation Loss', linewidth=2)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.savefig('loss_curve.png', dpi=300, bbox_inches='tight')\nprint(\" Loss curve saved to loss_curve.png\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TRAINING and EVALUATION COMPLETE!\")\nprint(\"=\"*70)\nprint(\"\\nNext steps:\")\nprint(\"1. Check loss_curve.png for training progress\")\nprint(\"2. Run evaluation metrics on test set\")\nprint(\"3. Display sample predictions\")\nprint(\"4. Deploy with Streamlit app\")\n      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:07:29.774774Z","iopub.execute_input":"2026-02-15T07:07:29.775093Z","iopub.status.idle":"2026-02-15T07:20:55.799411Z","shell.execute_reply.started":"2026-02-15T07:07:29.775067Z","shell.execute_reply":"2026-02-15T07:20:55.798791Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nPART 4: TRAINING and INFERENCE\n======================================================================\n Training samples: 127132\n Validation samples: 31783\nUsing device: cuda\n\nStarting training for 15 epochs...\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/15: 100%|██████████| 1987/1987 [00:47<00:00, 42.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 4.3132, Val Loss = 3.6179\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 1987/1987 [00:47<00:00, 41.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 3.5877, Val Loss = 3.3380\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 1987/1987 [00:48<00:00, 40.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 3.3699, Val Loss = 3.2022\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 1987/1987 [00:49<00:00, 40.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 3.2374, Val Loss = 3.1196\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 1987/1987 [00:49<00:00, 40.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 3.1458, Val Loss = 3.0656\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 1987/1987 [00:49<00:00, 39.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 3.0743, Val Loss = 3.0257\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 1987/1987 [00:49<00:00, 39.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 3.0155, Val Loss = 2.9963\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 1987/1987 [00:49<00:00, 39.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 2.9694, Val Loss = 2.9701\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 1987/1987 [00:49<00:00, 39.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 2.9275, Val Loss = 2.9554\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 1987/1987 [00:50<00:00, 39.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 2.8928, Val Loss = 2.9409\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 1987/1987 [00:50<00:00, 39.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 2.8622, Val Loss = 2.9296\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 1987/1987 [00:49<00:00, 39.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 2.8324, Val Loss = 2.9184\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 1987/1987 [00:50<00:00, 39.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 2.8081, Val Loss = 2.9084\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 1987/1987 [00:49<00:00, 39.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 2.7849, Val Loss = 2.9060\n   Best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 1987/1987 [00:50<00:00, 39.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 2.7638, Val Loss = 2.9004\n   Best model saved!\n\n Training complete!\n Loss curve saved to loss_curve.png\n\n======================================================================\nTRAINING and EVALUATION COMPLETE!\n======================================================================\n\nNext steps:\n1. Check loss_curve.png for training progress\n2. Run evaluation metrics on test set\n3. Display sample predictions\n4. Deploy with Streamlit app\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"\"\"\"\nEvaluation Metrics for Image Captioning\nIncludes BLEU-4, Precision, Recall, F1-Score, METEOR, and ROUGE\n\"\"\"\n\nimport numpy as np\nfrom collections import Counter\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\nfrom nltk.translate.meteor_score import meteor_score\nfrom rouge_score import rouge_scorer\n\n\nclass CaptionEvaluator:\n    \"\"\"Comprehensive evaluation metrics for image captioning\"\"\"\n    \n    def __init__(self):\n        # Download required NLTK data\n        try:\n            nltk.data.find('tokenizers/punkt')\n        except LookupError:\n            nltk.download('punkt', quiet=True)\n        \n        try:\n            nltk.data.find('corpora/wordnet')\n        except LookupError:\n            nltk.download('wordnet', quiet=True)\n        \n        self.smoothing = SmoothingFunction()\n    \n    def tokenize(self, text):\n        \"\"\"Tokenize text into words\"\"\"\n        return text.lower().split()\n    \n    def compute_bleu(self, references, hypotheses, max_n=4):\n        \"\"\"\n        Compute BLEU scores (BLEU-1 to BLEU-4)\n        Args:\n            references: list of lists of reference captions (tokenized)\n            hypotheses: list of hypothesis captions (tokenized)\n            max_n: maximum n-gram order\n        Returns:\n            dict with BLEU-1, BLEU-2, BLEU-3, BLEU-4 scores\n        \"\"\"\n        bleu_scores = {}\n        \n        for n in range(1, max_n + 1):\n            weights = tuple([1.0/n] * n + [0.0] * (4-n))\n            score = corpus_bleu(\n                references, \n                hypotheses, \n                weights=weights,\n                smoothing_function=self.smoothing.method1\n            )\n            bleu_scores[f'BLEU-{n}'] = score\n        \n        return bleu_scores\n    \n    def compute_precision_recall_f1(self, references, hypotheses):\n        \"\"\"\n        Compute token-level Precision, Recall, and F1-Score\n        Args:\n            references: list of lists of reference captions (strings)\n            hypotheses: list of hypothesis captions (strings)\n        Returns:\n            dict with precision, recall, f1 scores\n        \"\"\"\n        total_precision = 0\n        total_recall = 0\n        total_f1 = 0\n        count = 0\n        \n        for refs, hyp in zip(references, hypotheses):\n            # Tokenize\n            hyp_tokens = set(self.tokenize(hyp))\n            \n            # For multiple references, use the one with highest overlap\n            best_precision = 0\n            best_recall = 0\n            best_f1 = 0\n            \n            for ref in refs:\n                ref_tokens = set(self.tokenize(ref))\n                \n                if len(hyp_tokens) == 0:\n                    precision = 0\n                else:\n                    precision = len(hyp_tokens & ref_tokens) / len(hyp_tokens)\n                \n                if len(ref_tokens) == 0:\n                    recall = 0\n                else:\n                    recall = len(hyp_tokens & ref_tokens) / len(ref_tokens)\n                \n                if precision + recall == 0:\n                    f1 = 0\n                else:\n                    f1 = 2 * (precision * recall) / (precision + recall)\n                \n                if f1 > best_f1:\n                    best_precision = precision\n                    best_recall = recall\n                    best_f1 = f1\n            \n            total_precision += best_precision\n            total_recall += best_recall\n            total_f1 += best_f1\n            count += 1\n        \n        return {\n            'Precision': total_precision / count if count > 0 else 0,\n            'Recall': total_recall / count if count > 0 else 0,\n            'F1-Score': total_f1 / count if count > 0 else 0\n        }\n    \n    def compute_meteor(self, references, hypotheses):\n        \"\"\"\n        Compute METEOR score\n        Args:\n            references: list of lists of reference captions (strings)\n            hypotheses: list of hypothesis captions (strings)\n        Returns:\n            average METEOR score\n        \"\"\"\n        scores = []\n        \n        for refs, hyp in zip(references, hypotheses):\n            # METEOR expects tokenized strings\n            hyp_tokens = self.tokenize(hyp)\n            ref_tokens_list = [self.tokenize(ref) for ref in refs]\n            \n            # Compute METEOR for each reference and take max\n            ref_scores = [meteor_score(ref_tokens, hyp_tokens) for ref_tokens in ref_tokens_list]\n            scores.append(max(ref_scores))\n        \n        return np.mean(scores)\n    \n    def compute_rouge(self, references, hypotheses):\n        \"\"\"\n        Compute ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L)\n        Args:\n            references: list of lists of reference captions (strings)\n            hypotheses: list of hypothesis captions (strings)\n        Returns:\n            dict with ROUGE scores\n        \"\"\"\n        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        \n        rouge1_scores = []\n        rouge2_scores = []\n        rougeL_scores = []\n        \n        for refs, hyp in zip(references, hypotheses):\n            # Compute ROUGE for each reference and take max\n            max_rouge1 = 0\n            max_rouge2 = 0\n            max_rougeL = 0\n            \n            for ref in refs:\n                scores = scorer.score(ref, hyp)\n                max_rouge1 = max(max_rouge1, scores['rouge1'].fmeasure)\n                max_rouge2 = max(max_rouge2, scores['rouge2'].fmeasure)\n                max_rougeL = max(max_rougeL, scores['rougeL'].fmeasure)\n            \n            rouge1_scores.append(max_rouge1)\n            rouge2_scores.append(max_rouge2)\n            rougeL_scores.append(max_rougeL)\n        \n        return {\n            'ROUGE-1': np.mean(rouge1_scores),\n            'ROUGE-2': np.mean(rouge2_scores),\n            'ROUGE-L': np.mean(rougeL_scores)\n        }\n    \n    def evaluate_all(self, references, hypotheses):\n        \"\"\"\n        Compute all evaluation metrics\n        Args:\n            references: list of lists of reference captions\n                       e.g., [[ref1_img1, ref2_img1], [ref1_img2, ref2_img2], ...]\n            hypotheses: list of hypothesis captions\n                       e.g., [hyp_img1, hyp_img2, ...]\n        Returns:\n            dict with all metrics\n        \"\"\"\n        print(\"Computing evaluation metrics...\")\n        print(\"=\" * 60)\n        \n        # Prepare tokenized versions for BLEU\n        refs_tokenized = [[self.tokenize(r) for r in refs] for refs in references]\n        hyps_tokenized = [self.tokenize(h) for h in hypotheses]\n        \n        # BLEU scores\n        print(\"Computing BLEU scores...\")\n        bleu_scores = self.compute_bleu(refs_tokenized, hyps_tokenized)\n        \n        # Precision, Recall, F1\n        print(\"Computing Precision, Recall, F1...\")\n        prf_scores = self.compute_precision_recall_f1(references, hypotheses)\n        \n        # METEOR\n        print(\"Computing METEOR score...\")\n        try:\n            meteor = self.compute_meteor(references, hypotheses)\n            meteor_scores = {'METEOR': meteor}\n        except Exception as e:\n            print(f\"Warning: METEOR computation failed: {e}\")\n            meteor_scores = {'METEOR': 0.0}\n        \n        # ROUGE\n        print(\"Computing ROUGE scores...\")\n        try:\n            rouge_scores = self.compute_rouge(references, hypotheses)\n        except Exception as e:\n            print(f\"Warning: ROUGE computation failed: {e}\")\n            rouge_scores = {'ROUGE-1': 0.0, 'ROUGE-2': 0.0, 'ROUGE-L': 0.0}\n        \n        # Combine all metrics\n        all_metrics = {\n            **bleu_scores,\n            **prf_scores,\n            **meteor_scores,\n            **rouge_scores\n        }\n        \n        return all_metrics\n    \n    def print_metrics(self, metrics):\n        \"\"\"Print metrics in a formatted way\"\"\"\n        print(\"\\n\" + \"=\" * 60)\n        print(\"EVALUATION RESULTS\")\n        print(\"=\" * 60)\n        \n        # BLEU scores\n        print(\"\\nBLEU Scores:\")\n        for metric in ['BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4']:\n            if metric in metrics:\n                print(f\"  {metric}: {metrics[metric]:.4f}\")\n        \n        # Precision, Recall, F1\n        print(\"\\nToken-Level Metrics:\")\n        for metric in ['Precision', 'Recall', 'F1-Score']:\n            if metric in metrics:\n                print(f\"  {metric}: {metrics[metric]:.4f}\")\n        \n        # METEOR\n        if 'METEOR' in metrics:\n            print(f\"\\nMETEOR Score: {metrics['METEOR']:.4f}\")\n        \n        # ROUGE\n        print(\"\\nROUGE Scores:\")\n        for metric in ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']:\n            if metric in metrics:\n                print(f\"  {metric}: {metrics[metric]:.4f}\")\n        \n        print(\"=\" * 60)\n\n\ndef evaluate_model(model, test_data, features_dict, captions_df, vocab, \n                   device='cuda', method='greedy', num_samples=None):\n    \"\"\"\n    Evaluate model on test data\n    Args:\n        model: trained model\n        test_data: list of test samples\n        features_dict: dictionary of image features\n        captions_df: DataFrame with ground truth captions\n        vocab: vocabulary\n        device: device to use\n        method: 'greedy' or 'beam'\n        num_samples: number of samples to evaluate (None for all)\n    Returns:\n        metrics: dict of evaluation metrics\n        results: list of dicts with image, ground truth, and prediction\n    \"\"\"\n    if num_samples:\n        test_data = test_data[:num_samples]\n    \n    # Get unique images\n    test_images = list(set([item['image_name'] for item in test_data]))\n    \n    # Generate captions\n    print(f\"Generating captions for {len(test_images)} images using {method} search...\")\n    model.eval()\n    \n    predictions = []\n    references = []\n    results = []\n    \n    for img_name in test_images:\n        # Get ground truth captions\n        gt_captions = captions_df[captions_df['image'] == img_name]['caption'].tolist()\n        \n        if img_name not in features_dict:\n            continue\n        \n        # Generate caption\n        feature = torch.FloatTensor(features_dict[img_name]).unsqueeze(0).to(device)\n        pred_caption = model.generate_caption(feature, vocab, method=method)\n        \n        predictions.append(pred_caption)\n        references.append(gt_captions)\n        \n        results.append({\n            'image': img_name,\n            'ground_truth': gt_captions,\n            'prediction': pred_caption\n        })\n    \n    # Compute metrics\n    evaluator = CaptionEvaluator()\n    metrics = evaluator.evaluate_all(references, predictions)\n    evaluator.print_metrics(metrics)\n    \n    return metrics, results\n\n\nif __name__ == \"__main__\":\n    print(\"Evaluation Metrics Module\")\n    print(\"=\" * 60)\n    \n    # Example usage\n    print(\"\\nExample: Evaluating sample captions\")\n    print(\"-\" * 60)\n    \n    # Sample data\n    references = [\n        [\"a dog is running in the park\", \"a brown dog runs through grass\"],\n        [\"a woman holds a red umbrella\", \"woman with red umbrella standing\"]\n    ]\n    \n    hypotheses = [\n        \"a dog runs in the park\",\n        \"a woman with a red umbrella\"\n    ]\n    \n    # Evaluate\n    evaluator = CaptionEvaluator()\n    metrics = evaluator.evaluate_all(references, hypotheses)\n    evaluator.print_metrics(metrics)\n    \n    print(\"\\n Evaluation module ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:21:29.405421Z","iopub.execute_input":"2026-02-15T07:21:29.405764Z","iopub.status.idle":"2026-02-15T07:21:30.850119Z","shell.execute_reply.started":"2026-02-15T07:21:29.405736Z","shell.execute_reply":"2026-02-15T07:21:30.849500Z"}},"outputs":[{"name":"stdout","text":"Evaluation Metrics Module\n============================================================\n\nExample: Evaluating sample captions\n------------------------------------------------------------\nComputing evaluation metrics...\n============================================================\nComputing BLEU scores...\nComputing Precision, Recall, F1...\nComputing METEOR score...\nWarning: METEOR computation failed: \"reference\" expects pre-tokenized reference (Iterable[str]): a\nComputing ROUGE scores...\n\n============================================================\nEVALUATION RESULTS\n============================================================\n\nBLEU Scores:\n  BLEU-1: 1.0000\n  BLEU-2: 0.8944\n  BLEU-3: 0.5848\n  BLEU-4: 0.2403\n\nToken-Level Metrics:\n  Precision: 0.8167\n  Recall: 0.7571\n  F1-Score: 0.7846\n\nMETEOR Score: 0.0000\n\nROUGE Scores:\n  ROUGE-1: 0.8782\n  ROUGE-2: 0.6636\n  ROUGE-L: 0.8782\n============================================================\n\n✓ Evaluation module ready!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\"\"\"\nVisualization Module\nDisplay images with ground truth and predicted captions\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport os\nimport random\n\n\ndef display_caption_results(results, features_dict, image_dir, num_samples=5, save_path=None):\n    \"\"\"\n    Display images with ground truth and predicted captions\n    Args:\n        results: list of dicts with 'image', 'ground_truth', 'prediction'\n        features_dict: dict of image features (to verify image exists)\n        image_dir: directory containing images\n        num_samples: number of samples to display\n        save_path: path to save the figure (optional)\n    \"\"\"\n    # Select random samples\n    if len(results) > num_samples:\n        samples = random.sample(results, num_samples)\n    else:\n        samples = results\n    \n    # Create figure\n    fig, axes = plt.subplots(num_samples, 1, figsize=(12, 4*num_samples))\n    if num_samples == 1:\n        axes = [axes]\n    \n    for idx, (ax, result) in enumerate(zip(axes, samples)):\n        img_name = result['image']\n        img_path = os.path.join(image_dir, img_name)\n        \n        # Load image\n        try:\n            img = Image.open(img_path).convert('RGB')\n            ax.imshow(img)\n            ax.axis('off')\n            \n            # Get captions\n            gt_captions = result['ground_truth']\n            pred_caption = result['prediction']\n            \n            # Create title with ground truth and prediction\n            title = f\"Image: {img_name}\\n\\n\"\n            title += \"Ground Truth:\\n\"\n            \n            # Show up to 2 ground truth captions\n            for i, gt in enumerate(gt_captions[:2]):\n                title += f\"  • {gt}\\n\"\n            if len(gt_captions) > 2:\n                title += f\"  ... and {len(gt_captions)-2} more\\n\"\n            \n            title += f\"\\nPrediction:\\n  → {pred_caption}\"\n            \n            ax.set_title(title, fontsize=10, ha='left', pad=20)\n            \n        except Exception as e:\n            ax.text(0.5, 0.5, f\"Error loading image:\\n{img_name}\\n{str(e)}\", \n                   ha='center', va='center', fontsize=10)\n            ax.axis('off')\n    \n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        print(f\"Results saved to {save_path}\")\n    \n    return fig\n\n\ndef plot_metrics_comparison(metrics, save_path=None):\n    \"\"\"\n    Plot metrics as a bar chart\n    Args:\n        metrics: dict of metric names and values\n        save_path: path to save the figure (optional)\n    \"\"\"\n    # Separate BLEU and other metrics\n    bleu_metrics = {k: v for k, v in metrics.items() if 'BLEU' in k}\n    other_metrics = {k: v for k, v in metrics.items() if 'BLEU' not in k}\n    \n    # Create figure with two subplots\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Plot BLEU scores\n    if bleu_metrics:\n        names = list(bleu_metrics.keys())\n        values = list(bleu_metrics.values())\n        bars1 = ax1.bar(names, values, color='steelblue', alpha=0.8)\n        ax1.set_ylabel('Score', fontsize=12)\n        ax1.set_title('BLEU Scores', fontsize=14, fontweight='bold')\n        ax1.set_ylim(0, 1.0)\n        ax1.grid(True, alpha=0.3, axis='y')\n        \n        # Add value labels on bars\n        for bar in bars1:\n            height = bar.get_height()\n            ax1.text(bar.get_x() + bar.get_width()/2., height,\n                    f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n    \n    # Plot other metrics\n    if other_metrics:\n        names = list(other_metrics.keys())\n        values = list(other_metrics.values())\n        colors = plt.cm.Set3(np.linspace(0, 1, len(names)))\n        bars2 = ax2.bar(names, values, color=colors, alpha=0.8)\n        ax2.set_ylabel('Score', fontsize=12)\n        ax2.set_title('Other Metrics', fontsize=14, fontweight='bold')\n        ax2.set_ylim(0, 1.0)\n        ax2.grid(True, alpha=0.3, axis='y')\n        ax2.tick_params(axis='x', rotation=45)\n        \n        # Add value labels on bars\n        for bar in bars2:\n            height = bar.get_height()\n            ax2.text(bar.get_x() + bar.get_width()/2., height,\n                    f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n    \n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        print(f\"Metrics comparison saved to {save_path}\")\n    \n    return fig\n\n\ndef create_results_summary(metrics, train_losses, val_losses, \n                           num_epochs, save_path='results_summary.txt'):\n    \"\"\"\n    Create a text summary of all results\n    Args:\n        metrics: dict of evaluation metrics\n        train_losses: list of training losses\n        val_losses: list of validation losses\n        num_epochs: number of training epochs\n        save_path: path to save the summary\n    \"\"\"\n    with open(save_path, 'w') as f:\n        f.write(\"=\" * 60 + \"\\n\")\n        f.write(\"NEURAL STORYTELLER - IMAGE CAPTIONING RESULTS\\n\")\n        f.write(\"=\" * 60 + \"\\n\\n\")\n        \n        # Training summary\n        f.write(\"TRAINING SUMMARY\\n\")\n        f.write(\"-\" * 60 + \"\\n\")\n        f.write(f\"Number of Epochs: {num_epochs}\\n\")\n        f.write(f\"Final Training Loss: {train_losses[-1]:.4f}\\n\")\n        f.write(f\"Final Validation Loss: {val_losses[-1]:.4f}\\n\")\n        f.write(f\"Best Validation Loss: {min(val_losses):.4f}\\n\")\n        f.write(\"\\n\")\n        \n        # Evaluation metrics\n        f.write(\"EVALUATION METRICS\\n\")\n        f.write(\"-\" * 60 + \"\\n\")\n        \n        # BLEU scores\n        f.write(\"\\nBLEU Scores:\\n\")\n        for metric in ['BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4']:\n            if metric in metrics:\n                f.write(f\"  {metric}: {metrics[metric]:.4f}\\n\")\n        \n        # Token-level metrics\n        f.write(\"\\nToken-Level Metrics:\\n\")\n        for metric in ['Precision', 'Recall', 'F1-Score']:\n            if metric in metrics:\n                f.write(f\"  {metric}: {metrics[metric]:.4f}\\n\")\n        \n        # METEOR\n        if 'METEOR' in metrics:\n            f.write(f\"\\nMETEOR Score: {metrics['METEOR']:.4f}\\n\")\n        \n        # ROUGE\n        f.write(\"\\nROUGE Scores:\\n\")\n        for metric in ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']:\n            if metric in metrics:\n                f.write(f\"  {metric}: {metrics[metric]:.4f}\\n\")\n        \n        f.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n    \n    print(f\"Results summary saved to {save_path}\")\n\n\ndef display_random_predictions(model, features_dict, captions_df, vocab, \n                               image_dir, device='cuda', method='greedy', \n                               num_samples=5, save_path=None):\n    \"\"\"\n    Display random test predictions\n    Args:\n        model: trained model\n        features_dict: dict of image features\n        captions_df: DataFrame with ground truth captions\n        vocab: vocabulary object\n        image_dir: directory containing images\n        device: device to use\n        method: 'greedy' or 'beam'\n        num_samples: number of samples to display\n        save_path: path to save the figure\n    \"\"\"\n    # Get random images\n    all_images = list(features_dict.keys())\n    random_images = random.sample(all_images, min(num_samples, len(all_images)))\n    \n    # Generate predictions\n    results = []\n    model.eval()\n    \n    import torch\n    with torch.no_grad():\n        for img_name in random_images:\n            # Get ground truth\n            gt_captions = captions_df[captions_df['image'] == img_name]['caption'].tolist()\n            \n            # Generate prediction\n            feature = torch.FloatTensor(features_dict[img_name]).unsqueeze(0).to(device)\n            pred_caption = model.generate_caption(feature, vocab, method=method)\n            \n            results.append({\n                'image': img_name,\n                'ground_truth': gt_captions,\n                'prediction': pred_caption\n            })\n    \n    # Display\n    fig = display_caption_results(results, features_dict, image_dir, \n                                  num_samples, save_path)\n    return fig, results\n\n\nif __name__ == \"__main__\":\n    print(\"Visualization Module\")\n    print(\"=\" * 60)\n    \n    print(\"\\nAvailable Functions:\")\n    print(\"  1. display_caption_results() - Show images with captions\")\n    print(\"  2. plot_metrics_comparison() - Bar chart of metrics\")\n    print(\"  3. create_results_summary() - Text summary of results\")\n    print(\"  4. display_random_predictions() - Show random test predictions\")\n    \n    print(\"\\n Visualization module ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:25:24.701207Z","iopub.execute_input":"2026-02-15T07:25:24.702089Z","iopub.status.idle":"2026-02-15T07:25:24.724750Z","shell.execute_reply.started":"2026-02-15T07:25:24.702057Z","shell.execute_reply":"2026-02-15T07:25:24.724033Z"}},"outputs":[{"name":"stdout","text":"Visualization Module\n============================================================\n\nAvailable Functions:\n  1. display_caption_results() - Show images with captions\n  2. plot_metrics_comparison() - Bar chart of metrics\n  3. create_results_summary() - Text summary of results\n  4. display_random_predictions() - Show random test predictions\n\n Visualization module ready!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\"\"\"\nNeural Storyteller - Streamlit App\nInteractive web app for image captioning\n\"\"\"\n\nimport streamlit as st\nimport torch\nfrom PIL import Image\nimport pickle\nimport numpy as np\nfrom torchvision import models, transforms\nimport torch.nn as nn\nimport io\n\n# Set page config\nst.set_page_config(\n    page_title=\"Neural Storyteller\",\n    page_icon=\"\",\n    layout=\"wide\"\n)\n\n# Custom CSS\nst.markdown(\"\"\"\n    <style>\n    .main-header {\n        font-size: 3rem;\n        color: #1E88E5;\n        text-align: center;\n        margin-bottom: 2rem;\n    }\n    .subtitle {\n        font-size: 1.2rem;\n        color: #666;\n        text-align: center;\n        margin-bottom: 3rem;\n    }\n    .caption-box {\n        background-color: #f0f2f6;\n        padding: 1.5rem;\n        border-radius: 10px;\n        margin: 1rem 0;\n    }\n    .method-badge {\n        display: inline-block;\n        padding: 0.3rem 0.8rem;\n        border-radius: 15px;\n        font-size: 0.9rem;\n        font-weight: bold;\n        margin-right: 0.5rem;\n    }\n    .greedy {\n        background-color: #4CAF50;\n        color: white;\n    }\n    .beam {\n        background-color: #2196F3;\n        color: white;\n    }\n    </style>\n\"\"\", unsafe_allow_html=True)\n\n\n@st.cache_resource\ndef load_model_and_vocab(model_path, vocab_path):\n    \"\"\"Load the trained model and vocabulary\"\"\"\n    with open(vocab_path, 'rb') as f:\n        vocab = pickle.load(f)\n    \n    # Import model here to avoid circular imports\n    from part3_architecture import ImageCaptioningModel\n    \n    model = ImageCaptioningModel(vocab_size=len(vocab))\n    checkpoint = torch.load(model_path, map_location='cpu')\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    \n    return model, vocab\n\n\n@st.cache_resource\ndef load_feature_extractor():\n    \"\"\"Load ResNet50 for feature extraction\"\"\"\n    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n    model = nn.Sequential(*list(model.children())[:-1])\n    model.eval()\n    \n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ])\n    \n    return model, transform\n\n\ndef extract_features(image, feature_extractor, transform):\n    \"\"\"Extract features from an image\"\"\"\n    img_tensor = transform(image).unsqueeze(0)\n    \n    with torch.no_grad():\n        features = feature_extractor(img_tensor)\n        features = features.view(features.size(0), -1)\n    \n    return features\n\n\ndef generate_caption(features, model, vocab, method='greedy', beam_width=3):\n    \"\"\"Generate caption for image features\"\"\"\n    with torch.no_grad():\n        caption = model.generate_caption(\n            features, vocab, method=method, \n            beam_width=beam_width if method == 'beam' else 3\n        )\n    return caption\n\n\ndef main():\n    # Header\n    st.markdown('<h1 class=\"main-header\">Neural Storyteller</h1>', \n                unsafe_allow_html=True)\n    st.markdown('<p class=\"subtitle\">AI-Powered Image Captioning using Seq2Seq Architecture</p>', \n                unsafe_allow_html=True)\n    \n    # Sidebar\n    st.sidebar.title(\" Settings\")\n    \n    model_path = st.sidebar.text_input(\"Model Path\", \"best_model.pth\")\n    vocab_path = st.sidebar.text_input(\"Vocab Path\", \"vocab.pkl\")\n    \n    generation_method = st.sidebar.selectbox(\n        \"Generation Method\",\n        [\"Greedy Search\", \"Beam Search\"],\n        help=\"Greedy: Fast, selects most probable word. Beam: Slower, explores multiple possibilities.\"\n    )\n    \n    if generation_method == \"Beam Search\":\n        beam_width = st.sidebar.slider(\"Beam Width\", 2, 5, 3)\n    else:\n        beam_width = 3\n    \n    st.sidebar.markdown(\"---\")\n    st.sidebar.markdown(\"### About\")\n    st.sidebar.info(\n        \"This app uses a Seq2Seq model with:\\n\"\n        \"- **Encoder**: ResNet50 features → Hidden state\\n\"\n        \"- **Decoder**: LSTM with attention\\n\"\n        \"- **Training**: Flickr30k dataset\\n\"\n        \"- **Methods**: Greedy & Beam Search\"\n    )\n    \n    # Main content\n    col1, col2 = st.columns([1, 1])\n    \n    with col1:\n        st.subheader(\" Upload Image\")\n        uploaded_file = st.file_uploader(\n            \"Choose an image...\", \n            type=['jpg', 'jpeg', 'png'],\n            help=\"Upload an image to generate a caption\"\n        )\n        \n        if uploaded_file is not None:\n            image = Image.open(uploaded_file).convert('RGB')\n            st.image(image, caption='Uploaded Image', use_container_width=True)\n            \n            if st.button(\" Generate Caption\", type=\"primary\", use_container_width=True):\n                with st.spinner(\" Analyzing image...\"):\n                    try:\n                        model, vocab = load_model_and_vocab(model_path, vocab_path)\n                        feature_extractor, transform = load_feature_extractor()\n                        \n                        features = extract_features(image, feature_extractor, transform)\n                        \n                        method = 'greedy' if generation_method == \"Greedy Search\" else 'beam'\n                        \n                        caption = generate_caption(\n                            features, model, vocab, \n                            method=method, beam_width=beam_width\n                        )\n                        \n                        st.session_state['caption'] = caption\n                        st.session_state['method'] = generation_method\n                        \n                    except Exception as e:\n                        st.error(f\"Error generating caption: {str(e)}\")\n    \n    with col2:\n        st.subheader(\"📝 Generated Caption\")\n        \n        if 'caption' in st.session_state:\n            method_class = \"greedy\" if st.session_state['method'] == \"Greedy Search\" else \"beam\"\n            \n            st.markdown(\n                f'<div class=\"caption-box\">'\n                f'<span class=\"method-badge {method_class}\">{st.session_state[\"method\"]}</span>'\n                f'<h3 style=\"margin-top: 1rem;\">{st.session_state[\"caption\"]}</h3>'\n                f'</div>',\n                unsafe_allow_html=True\n            )\n            \n            st.info(\n                f\"**Method Used**: {st.session_state['method']}\\n\\n\"\n                f\"{'**Beam Width**: ' + str(beam_width) if st.session_state['method'] == 'Beam Search' else ''}\"\n            )\n            \n            st.download_button(\n                label=\"Download Caption\",\n                data=st.session_state['caption'],\n                file_name=\"generated_caption.txt\",\n                mime=\"text/plain\"\n            )\n        else:\n            st.info(\" Upload an image and click 'Generate Caption' to see results!\")\n    \n    # Footer\n    st.markdown(\"---\")\n    st.markdown(\n        \"<p style='text-align: center; color: #666;'>\"\n        \"Built with using PyTorch and Streamlit | Neural Storyteller v1.0\"\n        \"</p>\",\n        unsafe_allow_html=True\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T07:25:38.887521Z","iopub.execute_input":"2026-02-15T07:25:38.888181Z","iopub.status.idle":"2026-02-15T07:25:38.904989Z","shell.execute_reply.started":"2026-02-15T07:25:38.888151Z","shell.execute_reply":"2026-02-15T07:25:38.904045Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3135002710.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"],"ename":"ModuleNotFoundError","evalue":"No module named 'streamlit'","output_type":"error"}],"execution_count":10}]}